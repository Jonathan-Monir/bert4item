{
    "dataset": "template",
    "dataloader": {
        "sequence_len": 200,
        "mlm_mask_prob": 0.15
    },
    "model": {
        "hidden_dim": 128,
        "num_heads": 2,
        "dropout_prob": 0.15
    },
    "train": {
        "epoch": 1,
        "patience": 1,
        "batch_size": 128,
        "optimizer": {
            "lr": 0.001
        }
    }
}
